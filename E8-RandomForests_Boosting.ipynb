{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8\n",
    "\n",
    "## Car Price Prediction\n",
    "\n",
    "Predict if the price of a car is low or high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "      <th>HighPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2016</td>\n",
       "      <td>29242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2015</td>\n",
       "      <td>26465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>2012</td>\n",
       "      <td>46739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>2017</td>\n",
       "      <td>41722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>2014</td>\n",
       "      <td>77669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  M_CamryLE  \\\n",
       "15   2016    29242        0           0            0         0          1   \n",
       "47   2015    26465        0           0            0         0          1   \n",
       "85   2012    46739        0           1            0         0          0   \n",
       "141  2017    41722        0           0            0         0          0   \n",
       "226  2014    77669        0           0            0         0          0   \n",
       "\n",
       "     M_CamrySE  M_CamryXLE  HighPrice  \n",
       "15           0           0          1  \n",
       "47           0           0          1  \n",
       "85           0           0          1  \n",
       "141          1           0          1  \n",
       "226          0           1          0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../ModeloAvanzadosDecisionTrees/dataTrain_carListings.zip')\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data['HighPrice'] = (data['Price'] > data['Price'].mean()).astype(int)\n",
    "data = data.drop(['Model', 'Price'], axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13150, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['HighPrice']\n",
    "X = data.drop(['HighPrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.1\n",
    "\n",
    "Estimate a Decision Tree Classifier Manually using the code created in the Notebook #13\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = None\n",
    "num_pct = 10\n",
    "max_features = None\n",
    "min_gain=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mileage\n"
     ]
    }
   ],
   "source": [
    "j = 1\n",
    "print(X.columns[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the variable in num_ctp points\n",
    "splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / num_pct).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only unique values for filter binary and few unique values features\n",
    "splits = np.unique(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.00000e+00, 1.58728e+04, 2.32508e+04, 2.98747e+04, 3.56432e+04,\n",
       "       4.16580e+04, 4.83404e+04, 6.16152e+04, 8.07292e+04, 1.06371e+05])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "filter_l = X.iloc[:, j] < splits[k]\n",
    "\n",
    "y_l = y.loc[filter_l]\n",
    "y_r = y.loc[~filter_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20562506325087826"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_l = gini(y_l)\n",
    "gini_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3991431537249346"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_r = gini(y_r)\n",
    "gini_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(X_col, y, split):\n",
    "    \"Calculate the gain of an split k on feature j\"\n",
    "    \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18496148274516044"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_impurity(X.iloc[:, j], y, splits[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # For all features\n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # For all splits\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # If only one observation\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calculate the best split\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # save tree and estimate prediction\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Laplace correction\n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    \n",
    "    # Check stooping criteria\n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # No stooping criteria was meet, then continue to create the partition\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Next iteration to each split\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 0.5795316301703163,\n",
       " 'level': 0,\n",
       " 'split': [1, 51704.54545454545],\n",
       " 'n_samples': 13150,\n",
       " 'gain': 0.23348567756020572,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 0.8377538829151733,\n",
       "  'level': 1,\n",
       "  'split': -1,\n",
       "  'n_samples': 8368,\n",
       "  'gain': 0.0359166442135464},\n",
       " 'sr': {'y_pred': 0,\n",
       "  'y_prob': 0.12771739130434784,\n",
       "  'level': 1,\n",
       "  'split': -1,\n",
       "  'n_samples': 4782,\n",
       "  'gain': 0.04846022210319853}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grow(X, y, level=0, min_gain=0.001, max_depth=1, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=3, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "      <th>HighPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2016</td>\n",
       "      <td>29242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2015</td>\n",
       "      <td>26465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  M_CamryLE  \\\n",
       "15  2016    29242        0           0            0         0          1   \n",
       "47  2015    26465        0           0            0         0          1   \n",
       "\n",
       "    M_CamrySE  M_CamryXLE  HighPrice  \n",
       "15          0           0          1  \n",
       "47          0           0          1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 0.5780753517930095,\n",
       " 'level': 0,\n",
       " 'split': [1, 52187.63636363637],\n",
       " 'n_samples': 8810,\n",
       " 'gain': 0.23872134898880762,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 0.8391583452211127,\n",
       "  'level': 1,\n",
       "  'split': [0, 2014.0],\n",
       "  'n_samples': 5606,\n",
       "  'gain': 0.03317687167496233,\n",
       "  'sl': {'y_pred': 0,\n",
       "   'y_prob': 0.36828644501278773,\n",
       "   'level': 2,\n",
       "   'split': [0, 2012.0],\n",
       "   'n_samples': 389,\n",
       "   'gain': 0.05908490521197157,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.08,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 98,\n",
       "    'gain': 0.01707452211653898},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.46757679180887374,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 291,\n",
       "    'gain': 0.036947257392555666}},\n",
       "  'sr': {'y_pred': 1,\n",
       "   'y_prob': 0.8743054224947308,\n",
       "   'level': 2,\n",
       "   'split': [0, 2015.0],\n",
       "   'n_samples': 5217,\n",
       "   'gain': 0.014933378976312917,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 0.7348484848484849,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 1450,\n",
       "    'gain': 0.02449522073718463},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 0.9278323162642611,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 3767,\n",
       "    'gain': 0.008300801773423822}}},\n",
       " 'sr': {'y_pred': 0,\n",
       "  'y_prob': 0.12133499688084841,\n",
       "  'level': 1,\n",
       "  'split': [0, 2014.0],\n",
       "  'n_samples': 3204,\n",
       "  'gain': 0.04366470703709979,\n",
       "  'sl': {'y_pred': 0,\n",
       "   'y_prob': 0.03787566899958831,\n",
       "   'level': 2,\n",
       "   'split': [0, 2012.0],\n",
       "   'n_samples': 2427,\n",
       "   'gain': 0.0044807442426036265,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.007571345369831101,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 1715,\n",
       "    'gain': 6.140801902596027e-05},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.11204481792717087,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 712,\n",
       "    'gain': 0.008448612165673108}},\n",
       "  'sr': {'y_pred': 0,\n",
       "   'y_prob': 0.38254172015404364,\n",
       "   'level': 2,\n",
       "   'split': [1, 69702.90909090909],\n",
       "   'n_samples': 777,\n",
       "   'gain': 0.040449309391888344,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.4899193548387097,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 494,\n",
       "    'gain': 0.024087071241494562},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.19649122807017544,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 283,\n",
       "    'gain': 0.025513433574225197}}}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Check if final node\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # If left node is empty only continue with right\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  # If right node is empty only continue with left\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree prediction with max_depth=None:\n",
    "The accuracy with maxdepth = None is 84.3% lower thant the accuracy found below with max depth= 6 (87.7%). We found that maxdepth with value 6 is higher than with higher values, tehrefore it seems that for this case the optimal max_depth seems to be 6. However in 8.3 Exercise we will analize the maxdepth effect in accuracy as wer vary this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8433179723502304"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=None, num_pct=10)\n",
    "y_pred=tree_predict(X_test, tree)\n",
    "#Obteniendo el Accuracy\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8771889400921659"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=6, num_pct=10)\n",
    "y_pred=tree_predict(X_test, tree)\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.2\n",
    "\n",
    "Estimate a Bagging of 10 Decision Tree Classifiers Manually using the code created in the Notebook #7\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2016</td>\n",
       "      <td>29242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2015</td>\n",
       "      <td>26465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>2012</td>\n",
       "      <td>46739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>2017</td>\n",
       "      <td>41722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>2014</td>\n",
       "      <td>77669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  M_CamryLE  \\\n",
       "15   2016    29242        0           0            0         0          1   \n",
       "47   2015    26465        0           0            0         0          1   \n",
       "85   2012    46739        0           1            0         0          0   \n",
       "141  2017    41722        0           0            0         0          0   \n",
       "226  2014    77669        0           0            0         0          0   \n",
       "\n",
       "     M_CamrySE  M_CamryXLE  \n",
       "15           0           0  \n",
       "47           0           0  \n",
       "85           0           0  \n",
       "141          1           0  \n",
       "226          0           1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisando que las clases estén balanceadas, esto se puede evidenciar ya que no hay diferencias significativas (57% y 42%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7621</td>\n",
       "      <td>0.579544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5529</td>\n",
       "      <td>0.420456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  percentage\n",
       "1   7621    0.579544\n",
       "0   5529    0.420456"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts().to_frame('count').assign(percentage = lambda x: x/x.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the 10 samples randomly with replacement ,this is  Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "# create bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the 10 tree classifiers and fitting them to the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(123) \n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "\n",
    "trees = {}\n",
    "for i in range(n_estimators):\n",
    "    trees[i] = DecisionTreeClassifier(max_features=\"sqrt\", max_depth=None, random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying majority Voting to the trees in order to predict\n",
    "#### Performing the ten predictionso over test set  with the tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>332784</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146436</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130476</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85618</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2  3  4  5  6  7  8  9\n",
       "332784  0  0  0  0  1  1  0  1  1  1\n",
       "146436  1  1  1  1  1  1  1  1  1  1\n",
       "130476  1  1  1  1  1  1  1  1  1  1\n",
       "85618   1  1  1  1  1  1  1  1  1  1\n",
       "75474   0  0  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict \n",
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_df.iloc[:, i] = trees[i].predict(X_test)\n",
    "\n",
    "y_pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarising  predictions for each observation telling us how many of the ten trees defined predicted one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332784     5\n",
       "146436    10\n",
       "130476    10\n",
       "85618     10\n",
       "75474      0\n",
       "330419     0\n",
       "205915    10\n",
       "2836       8\n",
       "250833    10\n",
       "126784     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.sum(axis=1)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Accuracy with max depth = None, and =6, in order to compare the result with the found above in exercise 8.1. \n",
    "We could see that in 8.1 Accuracy was: 84.3%  & 87.7%  with max depth =  None & 6 respectively \n",
    "And with 8.2             Accuracy is:  84.2%  & 87.9%  with  max depth = None & 6 respectively \n",
    "We can conclude that when using bagging and enssembling 10 trees the accuray is better with max depth in 6. There fore an improvement can be made by enssembling many trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8658823529411764"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_pred_df.sum(axis=1) >= (n_estimators / 2)).astype(np.int)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8423963133640553"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8790322580645161"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(123) \n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "\n",
    "trees = {}\n",
    "for i in range(n_estimators):\n",
    "    trees[i] = DecisionTreeClassifier(max_features=\"sqrt\", max_depth=6, random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])\n",
    "\n",
    "    # Predict \n",
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_df.iloc[:, i] = trees[i].predict(X_test)\n",
    "\n",
    "y_pred_df.head()\n",
    "\n",
    "y_pred_df.sum(axis=1)[:10]\n",
    "\n",
    "y_pred = (y_pred_df.sum(axis=1) >= (n_estimators / 2)).astype(np.int)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.3\n",
    "\n",
    "Implement the variable max_features on the Decision Tree Classifier created in 11.1.\n",
    "\n",
    "Compare the impact in the results by varing the parameter max_features\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 8.3\n",
    "Lets first define the tree_grow before making predictions to evaluate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "max_depth = None\n",
    "num_pct = 10\n",
    "max_features = None\n",
    "min_gain=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Following, we define the 3 functions neccesary for later grow the tree with the recursively function and then predicit. These three fuctions are: \n",
    "1. gini function based on the ymeans equations shown bellow\n",
    "2. gini_impurity function: calculates the impurity of the branches right or left, calculated based on gini equation substraction,  and depends of the feature, y, and the split\n",
    "3. Best split: returns the feature (x var), the split (based on percentice), and the gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gini\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)\n",
    "\n",
    "\n",
    "    # Defining gini_impurity \n",
    "def gini_impurity(X_col, y, split):\n",
    "    \"Calculate the gain of an split k on feature j\"\n",
    "    \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_\n",
    "\n",
    "\n",
    "# Definign Best Split Function, returns the freature (x var), the split (based on percentice), and the gain\n",
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # For all features\n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # For all splits\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the growth tree function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # If only one observation\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calculate the best split\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # save tree and estimate prediction\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Laplace correction\n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    \n",
    "    # Check stooping criteria\n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # No stooping criteria was meet, then continue to create the partition\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Next iteration to each split\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 0.5795316301703163,\n",
       " 'level': 0,\n",
       " 'split': -1,\n",
       " 'n_samples': 13150,\n",
       " 'gain': 0.23348567756020572}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grow(X, y, level=0, min_gain=0.001, max_depth=0, num_pct=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the tree_predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Check if final node\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # If left node is empty only continue with right\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  # If right node is empty only continue with left\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the parameter max_depth to apply the predict function on the tree over test data. Then calculating accuracy for each max_depth\n",
    "In the graph bellow, we can see how the accuracy at depth of 1 starts already in 84%, however as the max_depth increases the accuracy too, reaching its peak around 88% accuracy in a max_depth of 6, after that point, it start decreasing again, by the 14 depth is in 85%.  \n",
    "With this it can be concluded that more depth is better ONLY until certain point, too much depth starts to affect accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "results=pd.DataFrame(columns=['max_depth', 'Accuracy'])\n",
    "\n",
    "for depth in range(1,15):\n",
    "    tree=tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=depth, num_pct=10)\n",
    "    tree_predict(X_test, tree)\n",
    "    accuracy=metrics.accuracy_score(y_test,tree_predict(X_test, tree))\n",
    "    results = results.append({'max_depth': depth, 'Accuracy': accuracy}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "results.Accuracy=round(results.Accuracy,3)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.plot(results.max_depth, results.Accuracy)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  Accuracy\n",
       "0         0.0     0.582\n",
       "1         1.0     0.841\n",
       "2         2.0     0.861\n",
       "3         3.0     0.861\n",
       "4         4.0     0.865\n",
       "5         5.0     0.873\n",
       "6         6.0     0.877\n",
       "7         7.0     0.875\n",
       "8         8.0     0.873\n",
       "9         9.0     0.873\n",
       "10       10.0     0.865\n",
       "11       11.0     0.863\n",
       "12       12.0     0.856\n",
       "13       13.0     0.856\n",
       "14       14.0     0.850"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.4\n",
    "\n",
    "Estimate a Bagging of 10 Decision Tree Classifiers with `max_features = log(n_features)`\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Bagging Classifier with log(n_features) & comparing results with nfeatures= n_features\n",
    "\n",
    "As we already did manually the bagging algorithm in 8.2 exercise, here we are going to apply directly the baggingClassifier function from sklearn, and change the parameter n_stimators to make sure we estimate 10 decision trees as requested. \n",
    "Later we do the same but not wwith log(features) but with the number of features. We found that accuracy was 85.3% with log(n_features) and 84.7%. So in this case was better to use log, however the improvement is small, maybe as we increase stimators the difference could be higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1972245773362196"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features=X.shape[1]\n",
    "import math\n",
    "math.log(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8838227247857012, 0.853225806451613)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10,max_features = int(math.log(n_features)),  bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Camillo Rojas\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:611: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Daniel Camillo Rojas\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:616: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8689956331877728, 0.847926267281106)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, max_features = n_features,  bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.5\n",
    "\n",
    "Using sklearn, train a RandomForestClassifier\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.6\n",
    "\n",
    "Find the best parameters of the RandomForestClassifier (max_depth, max_features, n_estimators)\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.7 \n",
    "\n",
    "Using xgboost train a XGBClassifier \n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-86571ba3ed33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier()\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.8\n",
    "\n",
    "Using xgboost train a XGBClassifier \n",
    "\n",
    "Modify the parameters learning rate, gamma, colsample_bytree. Explain what each parameter means.\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
